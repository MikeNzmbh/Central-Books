from __future__ import annotations

import json
import logging
from concurrent.futures import ThreadPoolExecutor, TimeoutError
from typing import Any, Callable

from django.conf import settings
from pydantic import BaseModel, Field, ValidationError, field_validator

from companion.llm import call_companion_llm, LLMProfile
from .llm_tone import build_companion_preamble

logger = logging.getLogger(__name__)

LLMCallable = Callable[[str], str | None]


class BooksRankedIssue(BaseModel):
    severity: str
    title: str
    message: str
    related_journal_ids: list[int] = Field(default_factory=list)
    related_accounts: list[str] = Field(default_factory=list)

    @field_validator("severity", mode="before")
    @classmethod
    def _normalize_severity(cls, value: str):
        if not isinstance(value, str):
            raise ValueError("severity must be a string")
        sev = value.lower()
        if sev not in {"low", "medium", "high"}:
            raise ValueError("severity must be one of low|medium|high")
        return sev


class BooksReviewLLMResult(BaseModel):
    explanations: list[str] = Field(default_factory=list)
    ranked_issues: list[BooksRankedIssue] = Field(default_factory=list)
    suggested_checks: list[str] = Field(default_factory=list)


class BankRankedTransaction(BaseModel):
    transaction_id: str
    priority: str
    reason: str

    @field_validator("transaction_id", mode="before")
    @classmethod
    def _coerce_tx_id(cls, value: Any):
        if value is None:
            raise ValueError("transaction_id is required")
        return str(value)

    @field_validator("priority", mode="before")
    @classmethod
    def _normalize_priority(cls, value: str):
        if not isinstance(value, str):
            raise ValueError("priority must be a string")
        prio = value.lower()
        if prio not in {"low", "medium", "high"}:
            raise ValueError("priority must be one of low|medium|high")
        return prio


class BankReviewLLMResult(BaseModel):
    explanations: list[str] = Field(default_factory=list)
    ranked_transactions: list[BankRankedTransaction] = Field(default_factory=list)
    suggested_followups: list[str] = Field(default_factory=list)


class RankedDocument(BaseModel):
    document_id: str
    priority: str
    reason: str

    @field_validator("document_id", mode="before")
    @classmethod
    def _coerce_doc_id(cls, value: Any):
        if value is None:
            raise ValueError("document_id is required")
        return str(value)

    @field_validator("priority", mode="before")
    @classmethod
    def _normalize_priority(cls, value: str):
        if not isinstance(value, str):
            raise ValueError("priority must be a string")
        prio = value.lower()
        if prio not in {"low", "medium", "high"}:
            raise ValueError("priority must be one of low|medium|high")
        return prio


class SuggestedClassification(BaseModel):
    document_id: str
    suggested_account_code: str | None = None
    confidence: float | None = None
    reason: str

    @field_validator("document_id", mode="before")
    @classmethod
    def _coerce_doc_id(cls, value: Any):
        if value is None:
            raise ValueError("document_id is required")
        return str(value)

    @field_validator("confidence", mode="before")
    @classmethod
    def _validate_confidence(cls, value: Any):
        if value is None:
            return value
        try:
            num = float(value)
        except Exception as exc:
            raise ValueError("confidence must be numeric") from exc
        if num < 0 or num > 1:
            raise ValueError("confidence must be between 0 and 1")
        return num


class ReceiptsRunLLMResult(BaseModel):
    explanations: list[str] = Field(default_factory=list)
    ranked_documents: list[RankedDocument] = Field(default_factory=list)
    suggested_classifications: list[SuggestedClassification] = Field(default_factory=list)
    suggested_followups: list[str] = Field(default_factory=list)


class IssueLLMItem(BaseModel):
    title: str
    description: str
    recommended_action: str | None = None
    estimated_impact: str | None = None
    severity: str | None = None
    surface: str | None = None
    run_type: str | None = None
    run_id: str | int | None = None

    @field_validator("severity", mode="before")
    @classmethod
    def _normalize_severity(cls, value: Any):
        if value is None:
            return None
        sev = str(value).lower()
        if sev not in {"low", "medium", "high"}:
            raise ValueError("severity must be low|medium|high")
        return sev


class IssuesLLMResult(BaseModel):
    issues: list[IssueLLMItem] = Field(default_factory=list)


class CompanionStoryResult(BaseModel):
    """
    Pydantic model for the weekly story narrative generated by DeepSeek Reasoner.
    
    Used by generate_companion_story() to parse and validate LLM output.
    """
    overall_summary: str
    timeline_bullets: list[str] = Field(default_factory=list)


# Story generation has its own timeout since we have a quick fallback
# Reasoner model needs 10-30 seconds for chain-of-thought, so 15s is reasonable
STORY_TIMEOUT_SECONDS = 15


class InvoicesRunLLMResult(BaseModel):
    explanations: list[str] = Field(default_factory=list)
    ranked_documents: list[RankedDocument] = Field(default_factory=list)
    suggested_classifications: list[SuggestedClassification] = Field(default_factory=list)
    suggested_followups: list[str] = Field(default_factory=list)


def _call_with_timeout(func: Callable[[], str | None], timeout_seconds: int) -> str | None:
    with ThreadPoolExecutor(max_workers=1) as executor:
        future = executor.submit(func)
        try:
            return future.result(timeout=timeout_seconds)
        except TimeoutError:
            logger.warning("LLM reasoning call timed out after %s seconds", timeout_seconds)
            return None


def _invoke_llm(prompt: str, *, llm_client: LLMCallable | None, timeout_seconds: int | None) -> str | None:
    """
    Invoke LLM for reasoning tasks using LIGHT_CHAT profile (deepseek-chat).
    """
    # Use LIGHT_CHAT for faster responses (2-10s vs 30-60s for reasoner)
    client = llm_client or (lambda p: call_companion_llm(p, profile=LLMProfile.LIGHT_CHAT))
    timeout = timeout_seconds if timeout_seconds is not None else getattr(settings, "COMPANION_LLM_TIMEOUT_SECONDS", 30)
    try:
        if timeout and timeout > 0:
            return _call_with_timeout(lambda: client(prompt), timeout)
        return client(prompt)
    except Exception as exc:  # pragma: no cover - defensive
        logger.warning("LLM reasoning call failed: %s", exc)
        return None


def _strip_markdown_json(raw: str | None) -> str | None:
    """
    Strip markdown code block wrappers from LLM output.
    
    LLMs often return JSON wrapped in ```json...``` or ```...``` blocks.
    This extracts the pure JSON content.
    """
    if not raw:
        return raw
    text = raw.strip()
    # Handle ```json ... ``` or ``` ... ```
    if text.startswith("```"):
        # Find end of first line (the language hint line)
        first_newline = text.find("\n")
        if first_newline != -1:
            text = text[first_newline + 1:]
        # Strip trailing ```
        if text.rstrip().endswith("```"):
            text = text.rstrip()[:-3].rstrip()
    return text


def reason_about_books_review(
    *,
    metrics: dict,
    findings: list[dict],
    sample_journals: list[dict],
    user_name: str | None = None,
    risk_level: str = "medium",
    llm_client: LLMCallable | None = None,
    timeout_seconds: int | None = None,
) -> BooksReviewLLMResult | None:
    """
    Guardrailed LLM reasoning for books review runs. Returns None on failure/disabled.
    
    Args:
        user_name: Optional first name for personalized messaging.
        risk_level: One of 'low', 'medium', 'high', 'critical' for tone adjustment.
    """
    allowed_journal_ids = {int(j["id"]) for j in sample_journals if isinstance(j, dict) and j.get("id") is not None}
    allowed_accounts = set()
    for journal in sample_journals:
        for acct in journal.get("accounts", []):
            code = acct.get("code")
            if code:
                allowed_accounts.add(str(code))

    preamble = build_companion_preamble(user_name, risk_level, "books")
    system_prompt = preamble + (
        "\nOnly reason about the JSON provided. "
        "Do not invent transactions, dates, or amounts. Do not change numbers. "
        "Only reference journal_entry_ids or account codes that appear in the input. "
        "Respond with JSON only and no extra text."
    )

    expected_schema = {
        "explanations": ["short narrative sentences about the ledger health"],
        "ranked_issues": [
            {
                "severity": "low|medium|high",
                "title": "short title",
                "message": "explain the pattern using only provided numbers",
                "related_journal_ids": ["must come from input sample_journals"],
                "related_accounts": ["account codes present in input"],
            }
        ],
        "suggested_checks": ["short suggestions on where to look next"],
    }

    payload = {
        "metrics": metrics,
        "findings": findings,
        "sample_journals": sample_journals,
        "output_schema": expected_schema,
        "rules": [
            "Do not fabricate transactions, IDs, dates, or amounts.",
            "Only cite journal ids and account codes from sample_journals.",
            "Use concise, factual language.",
            "Return ONLY the JSON object described by output_schema.",
        ],
    }

    prompt = f"{system_prompt}\n\nDATA:\n{json.dumps(payload, default=str)}"
    raw = _invoke_llm(prompt, llm_client=llm_client, timeout_seconds=timeout_seconds)
    if not raw:
        return None

    try:
        stripped = _strip_markdown_json(raw)
        logger.debug("Books review LLM stripped response (first 200): %s", stripped[:200] if stripped else "EMPTY")
        parsed_json = json.loads(stripped)
    except Exception as e:
        logger.warning("Books review LLM returned non-JSON response. Error: %s, Raw (first 500 chars): %s", e, raw[:500] if raw else "EMPTY")
        return None

    try:
        result = BooksReviewLLMResult.model_validate(parsed_json)
    except ValidationError as exc:
        logger.warning("Books review LLM validation failed: %s", exc)
        return None

    cleaned_issues: list[BooksRankedIssue] = []
    for issue in result.ranked_issues:
        valid_journal_ids = [jid for jid in issue.related_journal_ids if jid in allowed_journal_ids]
        valid_accounts = [code for code in issue.related_accounts if code in allowed_accounts]
        cleaned_issues.append(
            issue.model_copy(update={"related_journal_ids": valid_journal_ids, "related_accounts": valid_accounts})
        )

    return result.model_copy(update={"ranked_issues": cleaned_issues})


def reason_about_bank_review(
    *,
    metrics: dict,
    transactions: list[dict],
    user_name: str | None = None,
    risk_level: str = "medium",
    llm_client: LLMCallable | None = None,
    timeout_seconds: int | None = None,
) -> BankReviewLLMResult | None:
    """
    Guardrailed LLM reasoning for bank review runs. Returns None on failure/disabled.
    
    Args:
        user_name: Optional first name for personalized messaging.
        risk_level: One of 'low', 'medium', 'high', 'critical' for tone adjustment.
    """
    allowed_ids = {str(tx["transaction_id"]) for tx in transactions if isinstance(tx, dict) and tx.get("transaction_id") is not None}

    preamble = build_companion_preamble(user_name, risk_level, "bank")
    system_prompt = preamble + (
        "\nOnly reason about the JSON provided. "
        "Do not invent transactions, IDs, dates, or amounts. "
        "Return ONLY JSON with explanations, ranked_transactions, and suggested_followups."
    )

    expected_schema = {
        "explanations": ["1-2 sentence narrative about reconciliation status"],
        "ranked_transactions": [
            {"transaction_id": "<existing id from input>", "priority": "high|medium|low", "reason": "why this line matters"}
        ],
        "suggested_followups": ["concise next steps for a human reviewer"],
    }

    payload = {
        "metrics": metrics,
        "transactions": transactions,
        "output_schema": expected_schema,
        "rules": [
            "Only reference transaction_id values that were provided.",
            "Do not invent new amounts or balances; treat numerics descriptively.",
            "Keep reasons short and actionable.",
            "Respond with ONLY the JSON object described by output_schema.",
        ],
    }

    prompt = f"{system_prompt}\n\nDATA:\n{json.dumps(payload, default=str)}"
    raw = _invoke_llm(prompt, llm_client=llm_client, timeout_seconds=timeout_seconds)
    if not raw:
        return None

    try:
        parsed_json = json.loads(_strip_markdown_json(raw))
    except Exception:
        logger.warning("Bank review LLM returned non-JSON response.")
        return None

    try:
        result = BankReviewLLMResult.model_validate(parsed_json)
    except ValidationError as exc:
        logger.warning("Bank review LLM validation failed: %s", exc)
        return None

    cleaned: list[BankRankedTransaction] = []
    for tx in result.ranked_transactions:
        if str(tx.transaction_id) not in allowed_ids:
            continue
        cleaned.append(tx)

    return result.model_copy(update={"ranked_transactions": cleaned})


def reason_about_receipts_run(
    *,
    metrics: dict,
    documents: list[dict],
    user_name: str | None = None,
    risk_level: str = "medium",
    llm_client: LLMCallable | None = None,
    timeout_seconds: int | None = None,
) -> ReceiptsRunLLMResult | None:
    """
    Guardrailed LLM reasoning for receipts runs.
    
    Args:
        user_name: Optional first name for personalized messaging.
        risk_level: One of 'low', 'medium', 'high', 'critical' for tone adjustment.
    """
    allowed_ids = {str(doc["document_id"]) for doc in documents if isinstance(doc, dict) and doc.get("document_id") is not None}

    preamble = build_companion_preamble(user_name, risk_level, "receipts")
    system_prompt = preamble + (
        "\nOnly reason about the JSON provided. "
        "Do not invent receipts, amounts, vendors, or account codes. "
        "Return ONLY JSON with explanations, ranked_documents, suggested_classifications, suggested_followups."
    )
    expected_schema = {
        "explanations": ["short sentences summarizing risk and focus areas"],
        "ranked_documents": [
            {"document_id": "<existing id from input>", "priority": "high|medium|low", "reason": "why to review"}
        ],
        "suggested_classifications": [
            {
                "document_id": "<existing id from input>",
                "suggested_account_code": "string code if any",
                "confidence": "0-1",
                "reason": "short rationale",
            }
        ],
        "suggested_followups": ["concise next steps for a human reviewer"],
    }
    payload = {
        "metrics": metrics,
        "documents": documents,
        "output_schema": expected_schema,
        "rules": [
            "Only reference document_id values that were provided.",
            "Do not invent new amounts or vendors; rely only on the provided JSON.",
            "Suggested classifications are proposals only.",
            "Respond with ONLY the JSON object described by output_schema.",
        ],
    }
    prompt = f"{system_prompt}\n\nDATA:\n{json.dumps(payload, default=str)}"
    raw = _invoke_llm(prompt, llm_client=llm_client, timeout_seconds=timeout_seconds)
    if not raw:
        return None

    try:
        parsed_json = json.loads(_strip_markdown_json(raw))
    except Exception:
        logger.warning("Receipts run LLM returned non-JSON response.")
        return None

    try:
        result = ReceiptsRunLLMResult.model_validate(parsed_json)
    except ValidationError as exc:
        logger.warning("Receipts run LLM validation failed: %s", exc)
        return None

    ranked = [item for item in result.ranked_documents if str(item.document_id) in allowed_ids]
    suggested = [item for item in result.suggested_classifications if str(item.document_id) in allowed_ids]
    return result.model_copy(update={"ranked_documents": ranked, "suggested_classifications": suggested})


def reason_about_invoices_run(
    *,
    metrics: dict,
    documents: list[dict],
    user_name: str | None = None,
    risk_level: str = "medium",
    llm_client: LLMCallable | None = None,
    timeout_seconds: int | None = None,
) -> InvoicesRunLLMResult | None:
    """
    Guardrailed LLM reasoning for invoices runs.
    
    Args:
        user_name: Optional first name for personalized messaging.
        risk_level: One of 'low', 'medium', 'high', 'critical' for tone adjustment.
    """
    allowed_ids = {str(doc["document_id"]) for doc in documents if isinstance(doc, dict) and doc.get("document_id") is not None}

    preamble = build_companion_preamble(user_name, risk_level, "invoices")
    system_prompt = preamble + (
        "\nOnly reason about the JSON provided. "
        "Do not invent invoices, amounts, vendors, or account codes. "
        "Return ONLY JSON with explanations, ranked_documents, suggested_classifications, suggested_followups."
    )
    expected_schema = {
        "explanations": ["short sentences summarizing invoice health"],
        "ranked_documents": [
            {"document_id": "<existing id from input>", "priority": "high|medium|low", "reason": "why to review"}
        ],
        "suggested_classifications": [
            {
                "document_id": "<existing id from input>",
                "suggested_account_code": "string code if any",
                "confidence": "0-1",
                "reason": "short rationale",
            }
        ],
        "suggested_followups": ["concise next steps for a human reviewer"],
    }
    payload = {
        "metrics": metrics,
        "documents": documents,
        "output_schema": expected_schema,
        "rules": [
            "Only reference document_id values that were provided.",
            "Do not invent new amounts or vendors; rely only on the provided JSON.",
            "Suggested classifications are proposals only.",
            "Respond with ONLY the JSON object described by output_schema.",
        ],
    }
    prompt = f"{system_prompt}\n\nDATA:\n{json.dumps(payload, default=str)}"
    raw = _invoke_llm(prompt, llm_client=llm_client, timeout_seconds=timeout_seconds)
    if not raw:
        return None

    try:
        parsed_json = json.loads(_strip_markdown_json(raw))
    except Exception:
        logger.warning("Invoices run LLM returned non-JSON response.")
        return None

    try:
        result = InvoicesRunLLMResult.model_validate(parsed_json)
    except ValidationError as exc:
        logger.warning("Invoices run LLM validation failed: %s", exc)
        return None

    ranked = [item for item in result.ranked_documents if str(item.document_id) in allowed_ids]
    suggested = [item for item in result.suggested_classifications if str(item.document_id) in allowed_ids]
    return result.model_copy(update={"ranked_documents": ranked, "suggested_classifications": suggested})


def refine_companion_issues(
    issues: list[dict],
    user_name: str | None = None,
    risk_level: str = "medium",
    llm_client: LLMCallable | None = None,
    timeout_seconds: int | None = None,
) -> list[dict] | None:
    """
    Best-effort refinement/ranking of issue candidates. Returns None on failure so callers can fall back to deterministic issues.
    
    Args:
        user_name: Optional first name for personalized messaging.
        risk_level: One of 'low', 'medium', 'high', 'critical' for tone adjustment.
    """
    if not issues:
        return []

    preamble = build_companion_preamble(user_name, risk_level, "issues")
    system_prompt = preamble + (
        "\nGiven issue candidates, improve titles/descriptions/recommended actions, and assign severity (low|medium|high). "
        "Do NOT invent new data or suggest automatic postings or moving money. "
        "Only reason over the provided JSON. Keep text concise and businesslike."
    )
    payload = {"issues": issues}
    prompt = f"{system_prompt}\n\nDATA:\n{json.dumps(payload, default=str)}"
    raw = _invoke_llm(prompt, llm_client=llm_client, timeout_seconds=timeout_seconds)
    if not raw:
        return None
    try:
        parsed = json.loads(_strip_markdown_json(raw))
    except Exception:
        logger.warning("Issues refinement LLM returned non-JSON response.")
        return None
    try:
        result = IssuesLLMResult.model_validate(parsed)
    except ValidationError as exc:
        logger.warning("Issues refinement LLM validation failed: %s", exc)
        return None
    refined: list[dict] = []
    for item in result.issues:
        refined.append(
            {
                **{k: v for k, v in issues[0].items()},  # default keys if any
                "title": item.title,
                "description": item.description,
                "recommended_action": item.recommended_action or "",
                "estimated_impact": item.estimated_impact or "",
                "severity": (item.severity or "").lower() if item.severity else issues[0].get("severity"),
                "surface": item.surface or issues[0].get("surface"),
                "run_type": item.run_type or issues[0].get("run_type"),
                "run_id": item.run_id or issues[0].get("run_id"),
            }
        )
    return refined or issues


# ---------------------------------------------------------------------------
# COMPANION STORY MODE - Weekly narrative using DeepSeek Reasoner
# ---------------------------------------------------------------------------

STORY_SYSTEM_PROMPT = '''You are "CERN Companion," an AI accounting controller for small businesses.

STYLE:
- Speak directly to the user using their first name: "{first_name}".
- Tone: calm, friendly, professional.
- Be concise: 1 short paragraph + 2-4 bullet points max.
- Match urgency to focus_mode:
  - all_clear: relaxed and encouraging.
  - watchlist: gentle nudge, "worth a look soon".
  - fire_drill: clear and direct, but not panicked.

INPUT:
- A 4-axis radar with stability scores (0-100) for:
  - cash_reconciliation, revenue_invoices, expenses_receipts, tax_compliance
- Recent metrics for the last period.
- A small list of recent Companion issues with severities.
- The current focus_mode: {focus_mode}

TASK:
- Write a one-sentence overall summary of the business' recent state and direction.
- Then create 2-4 timeline_bullets highlighting what changed recently and what {first_name} should pay attention to, ordered by importance.
- Keep each bullet under 25 words.

CONSTRAINTS:
- Do NOT invent numbers, accounts, or transactions not implied by the data.
- Do NOT mention internal IDs or implementation details.
- Output must be valid JSON matching this schema exactly:
{{
  "overall_summary": "string",
  "timeline_bullets": ["string", ...]
}}
'''


def generate_companion_story(
    first_name: str | None,
    radar: dict,
    recent_metrics: dict,
    recent_issues: list,
    focus_mode: str,
    llm_client: LLMCallable | None = None,
    timeout_seconds: int | None = None,
) -> CompanionStoryResult | None:
    """
    Generate a weekly story narrative using DeepSeek Reasoner.
    
    This function has its own SHORT timeout (STORY_TIMEOUT_SECONDS = 5s by default)
    to ensure the companion summary API returns quickly. On timeout or error,
    the caller should use a deterministic fallback.
    
    Args:
        first_name: User's first name for personalization.
        radar: 4-axis stability scores from build_companion_radar().
        recent_metrics: Recent aggregate metrics (e.g., totals from last 30 days).
        recent_issues: List of recent CompanionIssue dicts with severity/title.
        focus_mode: One of "all_clear", "watchlist", "fire_drill".
        llm_client: Optional override for the LLM client (for testing).
        timeout_seconds: Optional timeout override (defaults to STORY_TIMEOUT_SECONDS).
    
    Returns:
        CompanionStoryResult with overall_summary and timeline_bullets, or None on failure/timeout.
    """
    # Use story-specific short timeout by default
    effective_timeout = timeout_seconds if timeout_seconds is not None else STORY_TIMEOUT_SECONDS
    
    name = first_name.strip().split()[0] if first_name and first_name.strip() else "there"
    
    try:
        # Build the system prompt with personalization
        system_prompt = STORY_SYSTEM_PROMPT.format(
            first_name=name,
            focus_mode=focus_mode,
        )
        
        # Prepare simplified issue data for the prompt
        issues_for_prompt = []
        for issue in recent_issues[:10]:  # Limit to 10 most recent
            if hasattr(issue, "title"):
                issues_for_prompt.append({
                    "title": issue.title,
                    "severity": issue.severity,
                    "surface": issue.surface,
                })
            elif isinstance(issue, dict):
                issues_for_prompt.append({
                    "title": issue.get("title", ""),
                    "severity": issue.get("severity", "low"),
                    "surface": issue.get("surface", ""),
                })
        
        # Build the user prompt with data
        user_prompt = f"""{system_prompt}

Here is the current data:

RADAR SCORES:
{json.dumps(radar, indent=2)}

RECENT METRICS:
{json.dumps(recent_metrics, indent=2)}

RECENT ISSUES:
{json.dumps(issues_for_prompt, indent=2)}

Please write the story narrative for {name}."""

        # Call DeepSeek Reasoner with short timeout
        raw = _invoke_llm(user_prompt, llm_client=llm_client, timeout_seconds=effective_timeout)
        if not raw:
            logger.warning("Story generation LLM returned no response (timeout or empty).")
            return None
        
        # Parse and validate
        try:
            parsed = json.loads(_strip_markdown_json(raw))
        except Exception:
            logger.warning("Story generation LLM returned non-JSON response.")
            return None
        
        result = CompanionStoryResult.model_validate(parsed)
        logger.info("Story generation succeeded for user '%s'", name)
        return result
        
    except ValidationError as exc:
        logger.warning("Story generation validation failed: %s", exc)
        return None
    except Exception as exc:
        # Catch-all for any unexpected errors - log and return None so fallback is used
        logger.warning("Story generation failed unexpectedly: %s", exc)
        return None


# ---------------------------------------------------------------------------
# Surface Subtitles Generation (DeepSeek-powered)
# ---------------------------------------------------------------------------

class SurfaceSubtitlesResult(BaseModel):
    """Result of surface subtitle generation."""
    receipts: str = Field(default="")
    invoices: str = Field(default="")
    books: str = Field(default="")
    bank: str = Field(default="")


def generate_surface_subtitles(
    *,
    user_name: str | None = None,
    surfaces_data: dict,
    llm_client: LLMCallable | None = None,
    timeout_seconds: int | None = None,
) -> SurfaceSubtitlesResult | None:
    """
    Generate personalized subtitles for each Companion surface via DeepSeek.
    
    Args:
        user_name: User's first name for personalization.
        surfaces_data: Dict with keys like 'receipts', 'invoices', 'books', 'bank'
                       containing coverage, issue counts, and recent run data.
        llm_client: Optional override for testing.
        timeout_seconds: Override for LLM timeout (default: 30s for fast response).
    
    Returns:
        SurfaceSubtitlesResult with short, personalized subtitles for each surface,
        or None if LLM fails.
    """
    effective_timeout = timeout_seconds if timeout_seconds is not None else 30
    name = user_name or "there"
    
    # Build a prompt that asks for all subtitles at once (more efficient)
    system_prompt = f"""You are a financial companion assistant. Generate SHORT, friendly subtitles (1-2 sentences max) for each surface.

RULES:
- Be warm and personal - address {name} directly
- Be specific about what you see in the data
- Each subtitle should be under 120 characters
- Don't use generic phrases - reference actual numbers when possible
- ONLY return valid JSON, no extra text

TONE EXAMPLES:
- "You've got 3 receipts waiting - quick categorization will keep things tidy."
- "Two invoices are overdue - a gentle nudge to clients might help."
- "Your books look balanced this week - nice work keeping it clean."
- "12 bank transactions need matching - 10 minutes should clear them."
"""

    user_prompt = f"""Generate personalized subtitles for {name}'s dashboard surfaces.

DATA:
{json.dumps(surfaces_data, indent=2, default=str)}

Return ONLY this JSON format:
{{
    "receipts": "<subtitle for receipts/expenses surface>",
    "invoices": "<subtitle for invoices surface>",
    "books": "<subtitle for books review surface>",
    "bank": "<subtitle for bank/cash surface>"
}}"""

    try:
        raw = _invoke_llm(
            f"{system_prompt}\n\n{user_prompt}",
            llm_client=llm_client,
            timeout_seconds=effective_timeout,
        )
        if not raw:
            logger.warning("Surface subtitles LLM returned no response.")
            return None
        
        try:
            parsed = json.loads(_strip_markdown_json(raw))
        except Exception:
            logger.warning("Surface subtitles LLM returned non-JSON: %s", raw[:200] if raw else "EMPTY")
            return None
        
        result = SurfaceSubtitlesResult.model_validate(parsed)
        logger.info("Surface subtitles generated successfully for '%s'", name)
        return result
        
    except ValidationError as exc:
        logger.warning("Surface subtitles validation failed: %s", exc)
        return None
    except Exception as exc:
        logger.warning("Surface subtitles generation failed: %s", exc)
        return None

